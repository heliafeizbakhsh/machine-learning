# -*- coding: utf-8 -*-
"""h4.feizbakhsh.logistic_regression_with_R2_regularization_on_iris_dataset

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_A7q-4ZQ0mHJg3tdey2cLi7_QNsrT065
"""

import numpy as np
import pandas as pd
import seaborn as sns 
from matplotlib import pyplot as plt

from sklearn.datasets import load_iris

iris_dataset = load_iris()
iris = pd.DataFrame(iris_dataset.data, columns=iris_dataset.feature_names)
iris['class'] = iris_dataset.target
iris.head()

print(iris_dataset.DESCR)

correlation_matrix = iris.corr()
sns.heatmap(data=correlation_matrix, annot=True,cmap='Greys')

sns.set()
fig, axes = plt.subplots(1, 4, figsize=(20, 5))

features = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']
target = ['class']

sns.set_theme(style="ticks")
for i, col in enumerate(features):
  sns.stripplot(ax=axes[i], x=target[0], y=col, data=iris)

iris.isnull().sum()

from sklearn.model_selection import train_test_split

X = iris.iloc[:, [0, 1, 2, 3]].values
y = iris.iloc[:, 4].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)

print("X_train.shape: ", X_train.shape)
print("X_test.shape: ", X_test.shape)
print("Y_train.shape: ", y_train.shape)
print("Y_test.shape: ", y_test.shape)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report
from sklearn.linear_model import LogisticRegression

classifier = LogisticRegression(C= 1, penalty='l2', solver='lbfgs', multi_class='multinomial')
classifier.fit(X_train, y_train)

print("A list of class labels known to the classifier:\n{}\n".format(classifier.classes_))
print("Coefficient of the features:\n{}\n".format(classifier.coef_))
print("Intercept:\n{}\n".format(classifier.intercept_))
print("Maximum number of iterations taken for the solvers to converge:\n{}\n".format(classifier.n_iter_))

y_train_predict = classifier.predict(X_train)

confusionmatrix = confusion_matrix(y_train, y_train_predict)
accuracyscore = accuracy_score(y_train, y_train_predict)
precisionscore = precision_score(y_train, y_train_predict, average='macro')
recallscore = recall_score(y_train, y_train_predict, average='macro')
f1score = f1_score(y_train, y_train_predict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classification_report(y_train, y_train_predict)))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))
print("\n")

ax = plt.axes()
sns.heatmap(confusionmatrix, annot=True, annot_kws={"size": 30}, fmt='d',cmap="Greys", ax = ax )
ax.set_title('Confusion Matrix')
plt.show()

probs_y_train=classifier.predict_proba(X_train)

probs_y_train = np.round(probs_y_train, 2)

res = "{:<5} | {:<10} | {:<15} | {:<10} | {:<13} | {:<5}".format("No.", "y_train", "y_train_predict", "Setosa(%)", "versicolor(%)", "virginica(%)\n")
res += "-"*80+"\n"
res += "\n".join("{:<5} | {:<10} | {:<15} | {:<10} | {:<13} | {:<10}".
                 format(i, x, y, a, b, c) for i, x, y, a, b, c in zip(range(y_train.shape[0]), y_train, y_train_predict, probs_y_train[:,0], probs_y_train[:,1], probs_y_train[:,2]))

res += "\n"+"-"*80+"\n"
print(res)

y_test_predict = classifier.predict(X_test)

confusionmatrix = confusion_matrix(y_test, y_test_predict)
raccuracyscore = accuracy_score(y_test, y_test_predict)
precisionscore = precision_score(y_test, y_test_predict, average='macro')
recallscore = recall_score(y_test, y_test_predict, average='macro')
f1score = f1_score(y_test, y_test_predict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification_report\n{}'.format(classification_report(y_test, y_test_predict)))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))
print("\n")

ax = plt.axes()
sns.heatmap(confusionmatrix, annot=True, annot_kws={"size": 30}, fmt='d',cmap="Greys", ax = ax )
ax.set_title('Confusion Matrix')
plt.show()

probs_y=classifier.predict_proba(X_test)

probs_y = np.round(probs_y, 2)

res = "{:<5} | {:<10} | {:<14} | {:<10} | {:<13} | {:<5}".format("No.","y_test", "y_test_predict", "Setosa(%)", "versicolor(%)", "virginica(%)\n")
res += "-"*79+"\n"
res += "\n".join("{:<5} | {:<10} | {:<14} | {:<10} | {:<13} | {:<10}".
                 format(i, x, y, a, b, c) for i, x, y, a, b, c in zip(range(y_test.shape[0]), y_test, y_test_predict, probs_y[:,0], probs_y[:,1], probs_y[:,2]))
res += "\n"+"-"*79+"\n"
print(res)