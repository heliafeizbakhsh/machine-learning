# -*- coding: utf-8 -*-
"""san_francisco_crime_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1053YWBueDgBPqH908uXryz_e6917zQNv

# **San Francisco crime classification**

# **Needed to install cartopy in colab**
"""

# !apt-get -qq install python-cartopy python3-cartopy
# !pip install geoplot

"""# **Import packages**"""

# Commented out IPython magic to ensure Python compatibility.
import os
import re
import shutil
import zipfile
import warnings
import numpy as np
import pandas as pd
import urllib.request
import xgboost as xgb
import seaborn as sns
import geoplot as gplt
import geopandas as gpd
import contextily as ctx
from matplotlib import cm
from sklearn.svm import SVC
from xgboost import XGBClassifier
from shapely.geometry import Point
from matplotlib import pyplot as plt
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

warnings.filterwarnings("ignore")
# %matplotlib inline

"""# **Download dataset from kaggle**"""

# from google.colab import files
# files.upload()
# !mkdir ~/.kaggle
# !cp kaggle.json ~/.kaggle
# !chmod 600 ~/.kaggle/kaggle.json
# !kaggle competitions download -c sf-crime

"""# **Load data**"""

train = pd.read_csv('/content/train.csv.zip', parse_dates=['Dates'])
test = pd.read_csv('/content/test.csv.zip', parse_dates=['Dates'], index_col='Id')
print("Train shape: {}".format(train.shape))
print("Test shape: {}".format(test.shape))

"""# **Data exploration**"""

print("-" * 15 + " Train " + "-" * 14)
print('First date: ', str(train['Dates'].describe()['first']))
print('Last date: ', str(train['Dates'].describe()['last']))
print('Data shape ', train.shape)
print("-" * 15 + " Test " + "-" * 15)
print('First date: ', str(test['Dates'].describe()['first']))
print('Last date: ', str(test['Dates'].describe()['last']))
print('Data shape ', test.shape)

train.head()

test.head()

"""# **Dataset includes the following variables**
*   Dates - timestamp of the crime incident
*   Category - category of the crime incident. (This is our target variable.)
*   Descript - detailed description of the crime incident
*   DayOfWeek - the day of the week
*   PdDistrict - the name of the Police Department District
*   Resolution - The resolution of the crime incident
*   Address - the approximate street address of the crime incident
*   X - Longitude
*   Y - Latitude

# **Unique values**
"""

print("No. of category: {}".format(train['Category'].nunique()))
print("No. of Descript: {}".format(train['Descript'].nunique()))
print("No. of PdDistrict: {}".format(train['PdDistrict'].nunique()))
print("No. of Resolution: {}".format(train['Resolution'].nunique()))
print("No. of Address: {}".format(train['Address'].nunique()))

"""# **Train features data type**"""

train.dtypes

"""# **Duplicated rows**"""

print("Duplicated rows: {}".format(train.duplicated().sum()))

"""# **Drop duplicated rows**"""

train.drop_duplicates(inplace=True)

"""# **Dates & Day of the week**"""

col = sns.color_palette()

train['Date'] = train['Dates'].dt.date

plt.figure(figsize=(10, 6))
data = train.groupby('Date').count().iloc[:, 0]
sns.kdeplot(data=data, shade=True)
plt.axvline(x=data.median(), ymax=0.95, linestyle='--', color=col[1])
plt.annotate(
    'Median: ' + str(data.median()),
    xy=(data.median(), 0.004),
    xytext=(200, 0.005),
    arrowprops=dict(arrowstyle='->', color=col[1], shrinkB=10))
plt.title(
    'Distribution of number of incidents per day', fontdict={'fontsize': 16}, color='black')
plt.xlabel('Incidents', color='black')
plt.ylabel('Density', color='black')
plt.xticks(color= 'black')
plt.yticks(color= 'black')
plt.show()

data = train.groupby('DayOfWeek').count().iloc[:, 0]
data = data.reindex([
    'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday',
    'Sunday'
])

plt.figure(figsize=(10, 5))
with sns.axes_style("whitegrid"):
    ax = sns.barplot(
        data.index, (data.values / data.values.sum()) * 100,
        orient='v',
        palette=cm.ScalarMappable(cmap='brg').to_rgba(data.values))

plt.title('Incidents per Weekday', fontdict={'fontsize': 16}, color= 'black')
plt.xlabel('Weekday', color= 'black')
plt.ylabel('Incidents (%)', color= 'black')
plt.xticks(color= 'black')
plt.yticks(color= 'black')
plt.show()

"""# **Category**"""

data = train.groupby('Category').count().iloc[:, 0]
data = data.reindex(train['Category'].unique())
data = data.sort_values(ascending=False)

plt.figure(figsize=(10, 10))
with sns.axes_style("whitegrid"):
    ax = sns.barplot(
        (data.values / data.values.sum()) * 100,
        data.index,
        orient='h',
        palette="brg",)

plt.title('Incidents per Crime Category', fontdict={'fontsize': 16}, color='black')
plt.xlabel('Incidents (%)', color='black')
plt.ylabel('Category', color='black')
plt.xticks(color='black')
plt.yticks(color='black')
plt.show()

"""# **Police District**"""

# Downloading the shapefile of the area 
url = 'https://data.sfgov.org/api/geospatial/wkhw-cjsf?method=export&format=Shapefile'
with urllib.request.urlopen(url) as response, open('pd_data.zip', 'wb') as out_file:
    shutil.copyfileobj(response, out_file)
# Unzipping it
with zipfile.ZipFile('pd_data.zip', 'r') as zip_ref:
    zip_ref.extractall('pd_data')
# Loading to a geopandas dataframe
for filename in os.listdir('./pd_data/'):
    if re.match(".+\.shp", filename):
        pd_districts = gpd.read_file('./pd_data/'+filename)
        break
# Defining the coordinate system to longitude/latitude
pd_districts.crs={'init': 'epsg:4326'}

# Merging our train dataset with the geo-dataframe
pd_districts = pd_districts.merge(
    train.groupby('PdDistrict').count().iloc[:, [0]].rename(
        columns={'Dates': 'Incidents'}),
    how='inner',
    left_on='district',
    right_index=True,
    suffixes=('_x', '_y'))

# Transforming the coordinate system to Spherical Mercator for
# compatibility with the tiling background
pd_districts = pd_districts.to_crs({'init': 'epsg:3857'})

# Calculating the incidents per day for every district
train_days = train.groupby('Date').count().shape[0]
pd_districts['inc_per_day'] = pd_districts.Incidents/train_days

# Ploting the data
fig, ax = plt.subplots(figsize=(10, 10))
pd_districts.plot(
    column='inc_per_day',
    cmap='Reds',
    alpha=0.6,
    edgecolor='r',
    linestyle='-',
    linewidth=1,
    legend=True,
    ax=ax)

def add_basemap(ax, zoom, url='http://tile.stamen.com/terrain/tileZ/tileX/tileY.png'):
    """Function that add the tile background to the map"""
    xmin, xmax, ymin, ymax = ax.axis()
    basemap, extent = ctx.bounds2img(xmin, ymin, xmax, ymax, zoom=zoom, url=url)
    ax.imshow(basemap, extent=extent, interpolation='bilinear')
    # restore original x/y limits
    ax.axis((xmin, xmax, ymin, ymax))

# Adding the background
add_basemap(ax, zoom=11, url=ctx.sources.ST_TONER_LITE)

# Adding the name of the districts
for index in pd_districts.index:
    plt.annotate(
        pd_districts.loc[index].district,
        (pd_districts.loc[index].geometry.centroid.x,
         pd_districts.loc[index].geometry.centroid.y),
        color='#353535',
        fontsize='large',
        fontweight='heavy',
        horizontalalignment='center'
    )

ax.set_axis_off()
plt.show()

"""# **X** - *Longitude* **Y** - *Latitude*"""

def create_gdf(df):
  gdf = df.copy()
  gdf['Coordinates'] = list(zip(gdf['X'], gdf['Y']))
  gdf['Coordinates'] = gdf['Coordinates'].apply(Point)
  gdf = gpd.GeoDataFrame(
      gdf, geometry='Coordinates', crs={'init': 'epsg:4326'})
  return gdf

"""# **Outlier coordinates**"""

train_gdf = create_gdf(train)

world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))
ax = world.plot(color='white', edgecolor='black')
train_gdf.plot(ax=ax, color='red')
plt.show()

print(train_gdf.loc[train_gdf.Y > 50].count()[0])
# train_gdf.loc[train_gdf.Y > 50].sample(5)

"""# **Replace outlier coordinates**"""

train.replace({'X': -120.5, 'Y': 90.0}, np.NaN, inplace=True)
test.replace({'X': -120.5, 'Y': 90.0}, np.NaN, inplace=True)

imp = SimpleImputer(strategy='mean')

for district in train['PdDistrict'].unique():
    train.loc[train['PdDistrict'] == district, ['X', 'Y']] = imp.fit_transform(
        train.loc[train['PdDistrict'] == district, ['X', 'Y']])
    test.loc[test['PdDistrict'] == district, ['X', 'Y']] = imp.transform(
        test.loc[test['PdDistrict'] == district, ['X', 'Y']])

train_gdf = create_gdf(train)

world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))
ax = world.plot(color='white', edgecolor='black')
train_gdf.plot(ax=ax, color='red')
plt.show()

"""# **Geographic density of difference crimes**"""

crimes = train['Category'].unique().tolist()

pd_districts = pd_districts.to_crs({'init':'epsg:4326'})
sf_land = pd_districts.unary_union
sf_land = gpd.GeoDataFrame(gpd.GeoSeries(sf_land), crs={'init':'epsg:4326'})
sf_land = sf_land.rename(columns={0:'geometry'}).set_geometry('geometry')

fig, ax = plt.subplots(3, 3, sharex=True, sharey=True, figsize=(12,12))
for i , crime in enumerate(np.random.choice(crimes, size=9, replace=False)):
    data = train_gdf.loc[train_gdf['Category'] == crime]
    ax = fig.add_subplot(3, 3, i+1)
    gplt.kdeplot(data,
                 shade=True,
                 shade_lowest=False,
                 clip = sf_land.geometry,
                 cmap='Reds',
                 ax=ax)
    gplt.polyplot(sf_land, ax=ax)
    ax.set_title(crime) 
plt.suptitle('Geographic Density of Different Crimes')
fig.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

"""# **Data Preprocessing**"""

train['Date'] = train['Dates'].dt.date

train['Day'] = train['Dates'].dt.day
train['Month'] = train['Dates'].dt.month
train['Year'] = train['Dates'].dt.year

train['Hour'] = train['Dates'].dt.hour
train['Minute'] = train['Dates'].dt.minute
train['Second'] = train['Dates'].dt.second

train['n_days'] = (train['Date'] - train['Date'].min()).apply(lambda x: x.days)

train['DayOfWeek'] = train['Dates'].dt.weekday

train['Block'] = train['Address'].str.contains('block', case=False)
train['ST'] = train['Address'].str.contains('ST', case=False)

train["X_Y"] = train["X"] - train["Y"]
train["XY"] = train["X"] + train["Y"]

test['Date'] = test['Dates'].dt.date

test['Day'] = test['Dates'].dt.day
test['Month'] = test['Dates'].dt.month
test['Year'] = test['Dates'].dt.year

test['Hour'] = test['Dates'].dt.hour
test['Minute'] = test['Dates'].dt.minute
test['Second'] = test['Dates'].dt.second

test['n_days'] = (test['Date'] - test['Date'].min()).apply(lambda x: x.days)

test['DayOfWeek'] = test['Dates'].dt.weekday

test['Block'] = test['Address'].str.contains('block', case=False)
test['ST'] = test['Address'].str.contains('ST', case=False)

test["X_Y"] = test["X"] - test["Y"]
test["XY"] = test["X"] + test["Y"]

"""# **average number of incidents per hour**"""

data = train.groupby(['Hour', 'Date', 'Category'], as_index=False).count().iloc[:, :4]
data.rename(columns={'Dates': 'Incidents'}, inplace=True)
data = data.groupby(['Hour', 'Category'], as_index=False).mean()

crimes = train['Category'].unique().tolist()
data = data.loc[data['Category'].isin(np.random.choice(crimes, size=5, replace=False))]

sns.set_style("whitegrid")
fig, ax = plt.subplots(figsize=(14, 4))
ax = sns.lineplot(x='Hour', y='Incidents', data=data, hue='Category')
ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=6)
plt.suptitle('Average number of incidents per hour')
fig.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

"""# **PdDistrict encoding**"""

labelEncoderPdDistrict = LabelEncoder()

train['PdDistrict'] = labelEncoderPdDistrict.fit_transform(train['PdDistrict'])
test['PdDistrict'] = labelEncoderPdDistrict.transform(test['PdDistrict'])

"""# **Address encoding**"""

labelEncoderAdress = LabelEncoder()
labelEncoderAdress.fit(list(train['Address']) + list(test['Address']))

train['Address'] = labelEncoderAdress.transform(train['Address'])
test['Address'] = labelEncoderAdress.transform(test['Address'])

"""# **Category encoding**"""

labelEncoderCategory = LabelEncoder()

target = labelEncoderCategory.fit_transform(train['Category'])

"""# **Drop colums**"""

train.drop(['Dates','Date','Descript','Resolution', 'Category'], 1, inplace=True)

test.drop(['Dates','Date',], 1, inplace=True)

print("Train rows: {}".format(train.shape[0]))
print("-"*25)
print("Train columns: {}".format(train.shape[1]))
print("-"*25)
train.head(1)

print("Test rows: {}".format(test.shape[0]))
print("-"*25)
print("Test columns: {}".format(test.shape[1]))
print("-"*25)
test.head(1)

"""# **Train, validation test split**"""

X_train, X_validation, y_train, y_validation = train_test_split(train, target, test_size=0.2, random_state=42)
X_test = test

"""# **Algorithms and Techniques**
| **Algorithm** | **Parameters** |                                            
| :-----------:   |   :----------: |
| Logistic regression  | penalty= 'l1', C= 1, solver= 'saga', multi_class= 'ovr', max_iter= 1 |
| Logistic regression  | penalty= 'l1', C= 1, solver= 'saga', multi_class= 'multinomial', max_iter= 1 |
| Logistic regression  | penalty= 'l2', C= 1, solver= 'lbfgs', multi_class= 'ovr', max_iter= 1 |
| Logistic regression  | penalty= 'l2', C= 1, solver= 'lbfgs, multi_class= 'multinomial', max_iter= 1 |
| SVC           | C= 1.0, gamma= 0.1, kernel= 'rbf', max_iter= 1, probability= True |
| Decision Tree | criterion= 'gini', max_depth= 3, random_state= 42 |
| Random Forest | n_estimators=1, criterion='gini', max_depth= 3, random_state= 42 |
| AdaBoost      | base_estimator= None, n_estimators= 3|
| Gradient Boost | learning_rate= 0.1, n_estimators= 1, max_depth= 3, random_state= 42 |
| XGBoost       | n_estimators= 1, criterion= 'gini',learning_rate= 0.1, max_depth= 3 ,gamma= 10, reg_lambda= 1 , objective= 'multi:softmax', random_state= 42 |

# **LogisticRegression(penalty= 'l1', C= 1, solver= 'saga', multi_class= 'ovr', max_iter= 1)**
"""

logisticRegressionModel = LogisticRegression(penalty= 'l1', C= 1, solver= 'saga', multi_class= 'ovr', max_iter= 1)
logisticRegressionModel.fit(X_train, y_train)

print("A list of class labels known to the classifier:\n{}\n".format(logisticRegressionModel.classes_))
print("Coefficient of the features:\n{}\n".format(logisticRegressionModel.coef_))
print("Intercept:\n{}\n".format(logisticRegressionModel.intercept_))
print("Maximum number of iterations taken for the solvers to converge:\n{}\n".format(logisticRegressionModel.n_iter_))

"""# **Logistic regression y_train_predict**"""

logisticRegressionModelPredict = logisticRegressionModel.predict(X_train)

accuracyscore = accuracy_score(y_train, logisticRegressionModelPredict)
classificationreport = classification_report(y_train, logisticRegressionModelPredict)
precisionscore = precision_score(y_train, logisticRegressionModelPredict, average='macro')
recallscore = recall_score(y_train, logisticRegressionModelPredict, average='macro')
f1score = f1_score(y_train, logisticRegressionModelPredict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **Logistic regression y_validation_predict**"""

logisticRegressionModelPredict = logisticRegressionModel.predict(X_validation)


accuracyscore = accuracy_score(y_validation, logisticRegressionModelPredict)
classificationreport = classification_report(y_validation, logisticRegressionModelPredict)
precisionscore = precision_score(y_validation, logisticRegressionModelPredict, average='macro')
recallscore = recall_score(y_validation, logisticRegressionModelPredict, average='macro')
f1score = f1_score(y_validation, logisticRegressionModelPredict, average='macro')

print("\n")
print("The model performance for validation set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **Logistic regression y_test_predict_proba**"""

logisticRegressionModelPredict = logisticRegressionModel.predict(X_test)
logisticRegressionModelPredictProba = logisticRegressionModel.predict_proba(X_test)

logisticRegressionModelPredictProba = pd.DataFrame(logisticRegressionModelPredictProba,
                                                   columns=labelEncoderCategory.inverse_transform(np.linspace(0, 38, 39, dtype='int16')), 
                                                   index=test.index)
logisticRegressionModelPredictProba.head(1)

"""# **LogisticRegression(penalty= 'l1', C= 1, solver= 'saga', multi_class= 'multinomial', max_iter= 1)**"""

logisticRegressionModel = LogisticRegression(penalty= 'l1', C= 1, solver= 'saga', multi_class= 'multinomial', max_iter= 1)
logisticRegressionModel.fit(X_train, y_train)

print("A list of class labels known to the classifier:\n{}\n".format(labelEncoderCategory.inverse_transform(logisticRegressionModel.classes_)))
print("Coefficient of the features:\n{}\n".format(logisticRegressionModel.coef_))
print("Intercept:\n{}\n".format(logisticRegressionModel.intercept_))
print("Maximum number of iterations taken for the solvers to converge:\n{}\n".format(logisticRegressionModel.n_iter_))

"""# **Logistic regression y_train_predict**"""

logisticRegressionModelPredict = logisticRegressionModel.predict(X_train)

accuracyscore = accuracy_score(y_train, logisticRegressionModelPredict)
classificationreport = classification_report(y_train, logisticRegressionModelPredict)
precisionscore = precision_score(y_train, logisticRegressionModelPredict, average='macro')
recallscore = recall_score(y_train, logisticRegressionModelPredict, average='macro')
f1score = f1_score(y_train, logisticRegressionModelPredict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **Logistic regression y_validation_predict**"""

logisticRegressionModelPredict = logisticRegressionModel.predict(X_validation)

accuracyscore = accuracy_score(y_validation, logisticRegressionModelPredict)
classificationreport = classification_report(y_validation, logisticRegressionModelPredict)
precisionscore = precision_score(y_validation, logisticRegressionModelPredict, average='macro')
recallscore = recall_score(y_validation, logisticRegressionModelPredict, average='macro')
f1score = f1_score(y_validation, logisticRegressionModelPredict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **Logistic regression y_test_predict_proba**"""

logisticRegressionModelPredict = logisticRegressionModel.predict(X_test)
logisticRegressionModelPredictProba = logisticRegressionModel.predict_proba(X_test)

logisticRegressionModelPredictProba = pd.DataFrame(logisticRegressionModelPredictProba,
                                                   columns=labelEncoderCategory.inverse_transform(np.linspace(0, 38, 39, dtype='int16')), 
                                                   index=test.index)
logisticRegressionModelPredictProba.head(1)

"""# **LogisticRegression(penalty = 'l2', C = 1, solver= 'lbfgs', multi_class= 'ovr', max_iter= 1)**

"""

logisticRegressionModel = LogisticRegression(penalty = 'l2', C = 1, solver= 'lbfgs', multi_class= 'ovr', max_iter= 1)
logisticRegressionModel.fit(X_train, y_train)

print("A list of class labels known to the classifier:\n{}\n".format(logisticRegressionModel.classes_))
print("Coefficient of the features:\n{}\n".format(logisticRegressionModel.coef_))
print("Intercept:\n{}\n".format(logisticRegressionModel.intercept_))
print("Maximum number of iterations taken for the solvers to converge:\n{}\n".format(logisticRegressionModel.n_iter_))

"""# **Logistic regression y_train_predict**"""

logisticRegressionModelPredict = logisticRegressionModel.predict(X_train)

accuracyscore = accuracy_score(y_train, logisticRegressionModelPredict)
classificationreport = classification_report(y_train, logisticRegressionModelPredict)
precisionscore = precision_score(y_train, logisticRegressionModelPredict, average='macro')
recallscore = recall_score(y_train, logisticRegressionModelPredict, average='macro')
f1score = f1_score(y_train, logisticRegressionModelPredict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **Logistic regression y_validation_predict**"""

logisticRegressionModelPredict = logisticRegressionModel.predict(X_validation)

accuracyscore = accuracy_score(y_validation, logisticRegressionModelPredict)
classificationreport = classification_report(y_validation, logisticRegressionModelPredict)
precisionscore = precision_score(y_validation, logisticRegressionModelPredict, average='macro')
recallscore = recall_score(y_validation, logisticRegressionModelPredict, average='macro')
f1score = f1_score(y_validation, logisticRegressionModelPredict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **Logistic regression y_test_predict_proba**"""

logisticRegressionModelPredict = logisticRegressionModel.predict(X_test)
logisticRegressionModelPredictProba = logisticRegressionModel.predict_proba(X_test)

logisticRegressionModelPredictProba = pd.DataFrame(logisticRegressionModelPredictProba,
                                                   columns=labelEncoderCategory.inverse_transform(np.linspace(0, 38, 39, dtype='int16')), 
                                                   index=test.index)
logisticRegressionModelPredictProba.head(1)

"""# **LogisticRegression(penalty= 'l2', C= 1, solver= 'lbfgs', multi_class= 'multinomial', max_iter= 2)**"""

logisticRegressionModel = LogisticRegression(penalty= 'l2', C= 1, solver= 'lbfgs', multi_class= 'multinomial', max_iter= 2)
logisticRegressionModel.fit(X_train, y_train)

print("A list of class labels known to the classifier:\n{}\n".format(logisticRegressionModel.classes_))
print("Coefficient of the features:\n{}\n".format(logisticRegressionModel.coef_))
print("Intercept:\n{}\n".format(logisticRegressionModel.intercept_))
print("Maximum number of iterations taken for the solvers to converge:\n{}\n".format(logisticRegressionModel.n_iter_))

"""# **Logistic regression y_train_predict**"""

logisticRegressionModelPredict = logisticRegressionModel.predict(X_train)

accuracyscore = accuracy_score(y_train, logisticRegressionModelPredict)
classificationreport = classification_report(y_train, logisticRegressionModelPredict)
precisionscore = precision_score(y_train, logisticRegressionModelPredict, average='macro')
recallscore = recall_score(y_train, logisticRegressionModelPredict, average='macro')
f1score = f1_score(y_train, logisticRegressionModelPredict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **Logistic regression y_validation_predict**"""

logisticRegressionModelPredict = logisticRegressionModel.predict(X_validation)

accuracyscore = accuracy_score(y_validation, logisticRegressionModelPredict)
classificationreport = classification_report(y_validation, logisticRegressionModelPredict)
precisionscore = precision_score(y_validation, logisticRegressionModelPredict, average='macro')
recallscore = recall_score(y_validation, logisticRegressionModelPredict, average='macro')
f1score = f1_score(y_validation, logisticRegressionModelPredict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **Logistic regression y_test_predict_proba**"""

logisticRegressionModelPredict = logisticRegressionModel.predict(X_test)
logisticRegressionModelPredictProba = logisticRegressionModel.predict_proba(X_test)

logisticRegressionModelPredictProba = pd.DataFrame(logisticRegressionModelPredictProba,
                                                   columns=labelEncoderCategory.inverse_transform(np.linspace(0, 38, 39, dtype='int16')), 
                                                   index=test.index)
logisticRegressionModelPredictProba.head(1)

"""# **SVC(C= 1.0, gamma= 0.1, kernel= 'rbf', max_iter= 1, probability= True)**"""

supportVectorMachineModel = SVC(C= 1.0, gamma= 0.1, kernel= 'rbf', max_iter= 1, probability= True)
supportVectorMachineModel.fit(X_train, y_train)

print('Multipliers of parameter C for each class:\n{}\n'.format(supportVectorMachineModel.class_weight_))
print('Indices of support vectors:\n{}\n'.format(supportVectorMachineModel.support_))
print('Number of support vectors:\n{}\n'.format(supportVectorMachineModel.support_.shape))
print('Number of support vectors for each class:\n{}\n'.format(supportVectorMachineModel.n_support_))
print('Fit status: (0 if correctly fitted, 1 otherwise)\n{}\n'.format(supportVectorMachineModel.fit_status_))

"""# **SVC y_train_predict**"""

supportVectorMachineModelPredict = supportVectorMachineModel.predict(X_train)

accuracyscore = accuracy_score(y_train, supportVectorMachineModelPredict)
classificationreport = classification_report(y_train, supportVectorMachineModelPredict)
precisionscore = precision_score(y_train, supportVectorMachineModelPredict, average='macro')
recallscore = recall_score(y_train, supportVectorMachineModelPredict, average='macro')
f1score = f1_score(y_train, supportVectorMachineModelPredict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **SVC y_validation_predict**"""

supportVectorMachineModelPredict = supportVectorMachineModel.predict(X_validation)

accuracyscore = accuracy_score(y_validation, supportVectorMachineModelPredict)
classificationreport = classification_report(y_validation, supportVectorMachineModelPredict)
precisionscore = precision_score(y_validation, supportVectorMachineModelPredict, average='macro')
recallscore = recall_score(y_validation, supportVectorMachineModelPredict, average='macro')
f1score = f1_score(y_validation, supportVectorMachineModelPredict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **SVC y_test_predict_proba**"""

supportVectorMachineModelPredict = supportVectorMachineModel.predict(X_test)
supportVectorMachineModelPredictProba = supportVectorMachineModel.predict_proba(X_test)

supportVectorMachineModelPredictProba = pd.DataFrame(supportVectorMachineModelPredictProba,
                                                   columns=labelEncoderCategory.inverse_transform(np.linspace(0, 38, 39, dtype='int16')), 
                                                   index=test.index)
supportVectorMachineModelPredictProba.head(1)

"""# **DecisionTreeClassifier(criterion= 'gini', max_depth= 3, random_state= 42)**"""

decisionTreeClassifierModel = DecisionTreeClassifier(criterion= 'gini', max_depth= 3, random_state= 42)
decisionTreeClassifierModel.fit(X_train, y_train)

"""# **Decision tree tree**"""

from sklearn import tree
feature_names = ['DayOfWeek',	'PdDistrict',	'Address',	'X',	'Y',	'Day',	'Month',	'Year',	'Hour',	'Minute',	'Second',	'n_days',	'Block',	'ST',	'X_Y',	'XY']
class_names = labelEncoderCategory.inverse_transform(np.arange(39))
fig, axes = plt.subplots(figsize= (100,20))
decisionTreeClassifierTree = tree.plot_tree(decisionTreeClassifierModel,
               feature_names= feature_names,
               class_names= class_names,
               impurity= True,
               rounded= True,
               filled= True,
              #  proportion= True)
               )
for tree in decisionTreeClassifierTree:
    arrow = tree.arrow_patch
    if arrow is not None:
        arrow.set_edgecolor('black')
        arrow.set_linewidth(3)
plt.show()

"""# **Decision tree y_train_predict**"""

decisionTreeClassifierModelPredict = decisionTreeClassifierModel.predict(X_train)

accuracyscore = accuracy_score(y_train, decisionTreeClassifierModelPredict)
classificationreport = classification_report(y_train, decisionTreeClassifierModelPredict)
precisionscore = precision_score(y_train, decisionTreeClassifierModelPredict, average='macro')
recallscore = recall_score(y_train, decisionTreeClassifierModelPredict, average='macro')
f1score = f1_score(y_train, decisionTreeClassifierModelPredict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **Decision tree y_validation_predict**"""

decisionTreeClassifierModelPredict = decisionTreeClassifierModel.predict(X_validation)

accuracyscore = accuracy_score(y_validation, decisionTreeClassifierModelPredict)
classificationreport = classification_report(y_validation, decisionTreeClassifierModelPredict)
precisionscore = precision_score(y_validation, decisionTreeClassifierModelPredict, average='macro')
recallscore = recall_score(y_validation, decisionTreeClassifierModelPredict, average='macro')
f1score = f1_score(y_validation, decisionTreeClassifierModelPredict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **Decision tree y_test_predict_proba**"""

decisionTreeClassifierModelPredict = decisionTreeClassifierModel.predict(X_test)
decisionTreeClassifierModelPredictProba = decisionTreeClassifierModel.predict_proba(X_test)

decisionTreeClassifierModelPredictProba = pd.DataFrame(decisionTreeClassifierModelPredictProba,
                                                   columns=labelEncoderCategory.inverse_transform(np.linspace(0, 38, 39, dtype='int16')), 
                                                   index=test.index)
decisionTreeClassifierModelPredictProba.head(1)

"""# **RandomForestClassifier(n_estimators= 1, criterion= 'gini', max_depth= 3, random_state= 42)**"""

randomForestClassifierModel = RandomForestClassifier(n_estimators= 1, criterion= 'gini', max_depth= 3, random_state= 42)
randomForestClassifierModel.fit(X_train, y_train)

"""# **Random forest tree**"""

from sklearn import tree
feature_names = ['DayOfWeek',	'PdDistrict',	'Address',	'X',	'Y',	'Day',	'Month',	'Year',	'Hour',	'Minute',	'Second',	'n_days',	'Block',	'ST',	'X_Y',	'XY']
class_names = labelEncoderCategory.inverse_transform(np.arange(39))
fig, axes = plt.subplots(figsize= (100,20))
randomForestClassifierTree = tree.plot_tree(randomForestClassifierModel.estimators_[0],
               feature_names= feature_names,
               class_names= class_names,
               impurity= True,
               rounded= True,
               filled= True,
              #  proportion= True)
               )
for tree in randomForestClassifierTree:
    arrow = tree.arrow_patch
    if arrow is not None:
        arrow.set_edgecolor('black')
        arrow.set_linewidth(3)
plt.show()

print("Number of trees in forest: {}".format(len(randomForestClassifierModel.estimators_)))
print("Number of classes: {}".format(randomForestClassifierModel.n_classes_))
print("Number of features: {}".format(randomForestClassifierModel.n_features_))

"""# **Random forest y_train_predict**"""

randomForestClassifierModelPredict = randomForestClassifierModel.predict(X_train)

accuracyscore = accuracy_score(y_train, randomForestClassifierModelPredict)
classificationreport = classification_report(y_train, randomForestClassifierModelPredict)
precisionscore = precision_score(y_train, randomForestClassifierModelPredict, average='macro')
recallscore = recall_score(y_train, randomForestClassifierModelPredict, average='macro')
f1score = f1_score(y_train, randomForestClassifierModelPredict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **Random forest y_validation_predict**"""

randomForestClassifierModelPredict = randomForestClassifierModel.predict(X_validation)

accuracyscore = accuracy_score(y_validation, randomForestClassifierModelPredict)
classificationreport = classification_report(y_validation, randomForestClassifierModelPredict)
precisionscore = precision_score(y_validation, randomForestClassifierModelPredict, average='macro')
recallscore = recall_score(y_validation, randomForestClassifierModelPredict, average='macro')
f1score = f1_score(y_validation, randomForestClassifierModelPredict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **Random Forest y_test_predict_proba**"""

randomForestClassifierModelPredict = randomForestClassifierModel.predict(X_test)
randomForestClassifierModelPredictProba = randomForestClassifierModel.predict_proba(X_test)

randomForestClassifierModelPredictProba = pd.DataFrame(randomForestClassifierModelPredictProba,
                                                   columns=labelEncoderCategory.inverse_transform(np.linspace(0, 38, 39, dtype='int16')), 
                                                   index=test.index)
randomForestClassifierModelPredictProba.head(1)

"""# **AdaBoostClassifier(base_estimator= None, n_estimators= 3)**"""

adaBoostClassifierModel = AdaBoostClassifier(base_estimator= None, n_estimators= 3)
adaBoostClassifierModel.fit(X_train, y_train)

"""# **Adaboost tree**"""

from sklearn import tree
feature_names = ['DayOfWeek',	'PdDistrict',	'Address',	'X',	'Y',	'Day',	'Month',	'Year',	'Hour',	'Minute',	'Second',	'n_days',	'Block',	'ST',	'X_Y',	'XY']
class_names = labelEncoderCategory.inverse_transform(np.arange(39))
fig, axes = plt.subplots(figsize= (100,20))
adaBoostClassifierTree = tree.plot_tree(adaBoostClassifierModel.estimators_[0],
               feature_names= feature_names,
               class_names= class_names,
               impurity= True,
               rounded= True,
               filled= True,
              #  proportion= True)
               )
for tree in adaBoostClassifierTree:
    arrow = tree.arrow_patch
    if arrow is not None:
        arrow.set_edgecolor('black')
        arrow.set_linewidth(3)
plt.show()

"""# **AdaBoost y_train_predict**"""

adaBoostClassifierModelPredict = adaBoostClassifierModel.predict(X_train)

accuracyscore = accuracy_score(y_train, adaBoostClassifierModelPredict)
classificationreport = classification_report(y_train, adaBoostClassifierModelPredict)
precisionscore = precision_score(y_train, adaBoostClassifierModelPredict, average='macro')
recallscore = recall_score(y_train, adaBoostClassifierModelPredict, average='macro')
f1score = f1_score(y_train, adaBoostClassifierModelPredict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **AdaBoost y_validation_predict**"""

adaBoostClassifierModelPredict = adaBoostClassifierModel.predict(X_validation)

accuracyscore = accuracy_score(y_validation, adaBoostClassifierModelPredict)
classificationreport = classification_report(y_validation, adaBoostClassifierModelPredict)
precisionscore = precision_score(y_validation, adaBoostClassifierModelPredict, average='macro')
recallscore = recall_score(y_validation, adaBoostClassifierModelPredict, average='macro')
f1score = f1_score(y_validation, adaBoostClassifierModelPredict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **AdaBoost y_test_predict_proba**"""

adaBoostClassifierModelPredict = adaBoostClassifierModel.predict(X_test)
adaBoostClassifierModelPredictProba = adaBoostClassifierModel.predict_proba(X_test)

adaBoostClassifierModelPredictProba = pd.DataFrame(adaBoostClassifierModelPredictProba,
                                                   columns=labelEncoderCategory.inverse_transform(np.linspace(0, 38, 39, dtype='int16')),
                                                   index=test.index)
adaBoostClassifierModelPredictProba.head(1)

"""# **GradientBoostingClassifier(learning_rate= 0.1, n_estimators= 1, max_depth= 3, random_state= 42)**"""

gradientBoostingClassifierModel = GradientBoostingClassifier(learning_rate= 0.1, n_estimators= 1, max_depth= 3, random_state= 42)
gradientBoostingClassifierModel.fit(X_train, y_train)

"""# **Gradient boost tree**"""

from sklearn import tree
feature_names = ['DayOfWeek',	'PdDistrict',	'Address',	'X',	'Y',	'Day',	'Month',	'Year',	'Hour',	'Minute',	'Second',	'n_days',	'Block',	'ST',	'X_Y',	'XY']
class_names = labelEncoderCategory.inverse_transform(np.arange(39))
fig, axes = plt.subplots(figsize= (100,20))
gradientBoostingClassifierTree = tree.plot_tree(gradientBoostingClassifierModel.estimators_[0, 0],
               feature_names= feature_names,
               class_names= class_names,
               impurity= True,
               rounded= True,
               filled= True,
              #  proportion= True)
               )
for tree in gradientBoostingClassifierTree:
    arrow = tree.arrow_patch
    if arrow is not None:
        arrow.set_edgecolor('black')
        arrow.set_linewidth(3)
plt.show()

"""# **Gradient boost y_train_predict**"""

gradientBoostingClassifierModelPredict = gradientBoostingClassifierModel.predict(X_train)

accuracyscore = accuracy_score(y_train, gradientBoostingClassifierModelPredict)
classificationreport = classification_report(y_train, gradientBoostingClassifierModelPredict)
precisionscore = precision_score(y_train, gradientBoostingClassifierModelPredict, average='macro')
recallscore = recall_score(y_train, gradientBoostingClassifierModelPredict, average='macro')
f1score = f1_score(y_train, gradientBoostingClassifierModelPredict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **Gradient boost y_validation_predict**"""

gradientBoostingClassifierModelPredict = gradientBoostingClassifierModel.predict(X_validation)

accuracyscore = accuracy_score(y_validation, gradientBoostingClassifierModelPredict)
classificationreport = classification_report(y_validation, gradientBoostingClassifierModelPredict)
precisionscore = precision_score(y_validation, gradientBoostingClassifierModelPredict, average='macro')
recallscore = recall_score(y_validation, gradientBoostingClassifierModelPredict, average='macro')
f1score = f1_score(y_validation, gradientBoostingClassifierModelPredict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **Gradient boost y_test_predict_proba**"""

gradientBoostingClassifierModelPredict = gradientBoostingClassifierModel.predict(X_test)
gradientBoostingClassifierModelPredictProba = gradientBoostingClassifierModel.predict_proba(X_test)

gradientBoostingClassifierModelPredictProba = pd.DataFrame(gradientBoostingClassifierModelPredictProba,
                                                   columns=labelEncoderCategory.inverse_transform(np.linspace(0, 38, 39, dtype='int16')), index=test.index)
gradientBoostingClassifierModelPredictProba.head(1)

"""# **XGBClassifier(n_estimators= 1, criterion= 'gini',learning_rate= 0.1, max_depth= 3 ,gamma= 10, reg_lambda= 1, objective= 'multi:softmax', random_state= 42)**"""

XGBClassifierModel = XGBClassifier(n_estimators= 1, criterion= 'gini',learning_rate= 0.1, max_depth= 3 ,gamma= 10, reg_lambda= 1, 
                                   objective= 'multi:softmax', random_state= 42)
XGBClassifierModel.fit(X_train, y_train)

"""# **XGBoost tree**"""

node_params = {
    'shape': 'box',
    'style': 'filled, rounded',
    'fillcolor': '#78cbe'
}
leaf_params = {
    'shape': 'box',
    'style': 'filled',
    'fillcolor': '#e48038'
}
xgb.to_graphviz(XGBClassifierModel, size= "10, 10",
                condition_node_params= node_params,
                leaf_node_params= leaf_params)

"""# **XGBoost y_train_predict**"""

XGBClassifierModelPredict = XGBClassifierModel.predict(X_train)

accuracyscore = accuracy_score(y_train, XGBClassifierModelPredict)
classificationreport = classification_report(y_train, XGBClassifierModelPredict)
precisionscore = precision_score(y_train, XGBClassifierModelPredict, average='macro')
recallscore = recall_score(y_train, XGBClassifierModelPredict, average='macro')
f1score = f1_score(y_train, XGBClassifierModelPredict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **XGBoost y_validation_predict**"""

XGBClassifierModelPredict = XGBClassifierModel.predict(X_validation)

accuracyscore = accuracy_score(y_validation, XGBClassifierModelPredict)
classificationreport = classification_report(y_validation, XGBClassifierModelPredict)
precisionscore = precision_score(y_validation, XGBClassifierModelPredict, average='macro')
recallscore = recall_score(y_validation, XGBClassifierModelPredict, average='macro')
f1score = f1_score(y_validation, XGBClassifierModelPredict, average='macro')

print("\n")
print("The model performance for training set")
print("--------------------------------------")
print('classification report\n{}'.format(classificationreport))
print('accuracy score is {}\n'.format(accuracyscore))
print('precision score is {}\n'.format(precisionscore))
print('recall score is {}\n'.format(recallscore))
print('f1 score is {}'.format(f1score))

"""# **XGBoost y_test_predict_proba**"""

XGBClassifierModelPredict = XGBClassifierModel.predict(X_test)
XGBClassifierModelPredictProba = XGBClassifierModel.predict_proba(X_test)

XGBClassifierModelPredictProba = pd.DataFrame(XGBClassifierModelPredictProba,
                                                   columns=labelEncoderCategory.inverse_transform(np.linspace(0, 38, 39, dtype='int16')), 
                                              index=test.index)
XGBClassifierModelPredictProba.head(1)

"""  # **Sources:**

  1.   https://www.kaggle.com/c/sf-crime
  2.   https://docs.streamlit.io/en/stable/api.html
  3.   https://scikit-learn.org/stable/modules/classes.html
  4.   https://www.kaggle.com/yannisp/sf-crime-analysis-prediction
  5.   https://www.kaggle.com/sjun4530/sf-crime-classification-hyper/
  6.   https://xgboost.readthedocs.io/en/latest/python/python_api.html
  7.   https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html
  8.   https://www.youtube.com/playlist?list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF
  9.   https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html
  10.  https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html
  11.  https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html
  12.  https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html
  13.  https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html
"""